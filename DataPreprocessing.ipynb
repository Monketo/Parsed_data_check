{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Vocabscraper import VocabularyScraper\n",
    "import os\n",
    "import pickle\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from  nltk.tokenize import word_tokenize as tokenizer\n",
    "import itertools\n",
    "import string\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk import ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    ''' Helper function to load dataset '''\n",
    "    data=None\n",
    "    FILE_PATH= \"words.pkl\"\n",
    "    if not os.path.exists(FILE_PATH):\n",
    "        cursor = VocabularyScraper(None).db_executer\n",
    "        cursor.execute(\"SELECT term,definitions,examples FROM terms\")\n",
    "        data = cursor.fetchall()\n",
    "        with open(FILE_PATH,\"wb\") as file:\n",
    "            pickle.dump(data,file)\n",
    "    else:\n",
    "        with open(FILE_PATH,\"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def look_up_word(term,data):\n",
    "    '''Name of the function is self-explanatory '''\n",
    "        \n",
    "    for word in data:\n",
    "        if word[0]==term:\n",
    "            return word\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_optimum_length(defs_exs,percentiles):\n",
    "    \n",
    "    '''Name of the function is self-explanatory '''\n",
    "    \n",
    "    stats = [len(ex) for ex in defs_exs]\n",
    "    df= pandas.DataFrame(stats,columns=[\"length of samples\"])\n",
    "    return df.describe(percentiles=percentiles)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ex_remove_red_chars(*examples):\n",
    "    \n",
    "    ''' Function to remove redundant chars , like punctuation or part of speech markers\n",
    "        Then to split them using \"#$\" or \"&#\" delimiters'''\n",
    "    \n",
    "    result=[]\n",
    "    for example in examples:\n",
    "        if example is not None:\n",
    "            punctuation=re.sub(\"[#$&]*\",\"\",string.punctuation)\n",
    "            punctuation = [char for char in punctuation]\n",
    "            del_patterns = [\"&[\\w]+&\",'”',\"^[\\s]\",\"“\",\"adj\\n\",\"v\\n\",\"n\\n\",\"adv\\n\"]\n",
    "            del_patterns.extend(punctuation)\n",
    "            for pattern in del_patterns:\n",
    "                example = example.replace(pattern,\"\")\n",
    "            example = re.split(r\"[&#$]*;*\",example) \n",
    "            \n",
    "            result.append(example)\n",
    "        else:\n",
    "            result.append(\"\")\n",
    "    return tuple(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_duplicates(data):\n",
    "    ''' Function to avoid storing unneccessary duplicates'''\n",
    "    \n",
    "    terms= set()\n",
    "    defs_exs=set()\n",
    "   \n",
    "    \n",
    "    for word in data:\n",
    "        terms.add(word[0])\n",
    "        definitions,examples = word[1],word[2]\n",
    "        definitions,examples =  ex_remove_red_chars(definitions,examples)\n",
    "        defs_exs.update(definitions,examples)\n",
    "        \n",
    "    return(terms,defs_exs)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "terms , defs_exs = process_duplicates(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_dicts(terms,defs_and_exs):\n",
    "    \n",
    "    ''' Function to create helping dictionaries for future word-to-integers (or conversely) conversion'''\n",
    "    \n",
    "    all_text = list(itertools.chain(*[sent.split() for sent in list(defs_exs)]))\n",
    "    counter=Counter(all_text)\n",
    "    index=0\n",
    "    word_to_index=dict()\n",
    "    \n",
    "    for key,indx in counter.items():\n",
    "        word_to_index[key]=index\n",
    "        index+=1\n",
    "        \n",
    "    #Terms should be treated differently,avoiding split,that's why we add them seperately\n",
    "    \n",
    "    for word in terms:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word]=index\n",
    "            index+=1\n",
    "            \n",
    "    index_to_word=dict()\n",
    "    \n",
    "    for key,index in word_to_index.items():\n",
    "        index_to_word[index]=key\n",
    "    return (word_to_index,index_to_word)    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_to_index,index_to_word = create_lookup_dicts(terms,defs_exs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('person',\n",
       " 'a human body (usually including the clothing &$ A single human being; an individual &$ A linguistic category used to distinguish between the speaker of an utterance and those to whom or about whom he is speaking. See grammatical person &$ one of three relations or conditions (that of speaking, that of being spoken to, and that of being spoken of) pertaining to a noun or a pronoun, and thence also to the verb of which it may be the subject &$ a living, self-conscious being, as distinct from an animal or a thing; a moral agent; a human being; a man, woman, or child &$ Someone who likes or has an affinity for (a specified thing &$ a character or part, as in a play; a specific kind or manifestation of individual character, whether in real life, or in literary or dramatic representation; an assumed character &$ the bodily form of a human being; body; outward appearance; as, of comely person &$ a grammatical category used in the classification of pronouns, possessive determiners, and verb forms according to whether they indicate the speaker, the addressee, or a third party &$ a human being spoken of indefinitely; one; a man; as, any person present &$ Any individual or formal organization with standing before the courts &$ a human being &$ a parson; the parish priest &$ to represent as a person; to personify; to impersonate &$ The physical human body seen as distinct from the mind, character etc &$ a shoot or bud of a plant; a polyp or zooid of the compound Hydrozoa Anthozoa, etc.; also, an individual, in the narrowest sense, among the higher animals &$ among Trinitarians, one of the three subdivisions of the Godhead (the Father, the Son, and the Holy Ghost); an hypostasis',\n",
       " None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_up_word(\"person\",words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode(defs_exs,word2int):\n",
    "    '''Function to encode words to integers'''\n",
    "    sentences=[]\n",
    "    for example in defs_exs:\n",
    "        sentence=[]\n",
    "        for word in example.split():\n",
    "            sentence.append(word2int[word])\n",
    "        sentences.append(sentence) \n",
    "    encoded=np.array(sentences)\n",
    "    return encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoded=encode(defs_exs,word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[], [0, 1, 2, 3], [4, 5, 6, 7, 8, 9, 10, 11], ...,\n",
       "       [238, 13, 16695, 2048, 163, 244, 13, 18, 6117, 163, 3185, 183800],\n",
       "       [9998, 9, 5047, 34, 7182, 14323], [71499, 79241, 2517]], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def skipgrams(sequence, n, k):\n",
    "    ''' Can be deleted , was used for testing'''\n",
    "    for ngram in ngrams(sequence, n + k, pad_right=True):\n",
    "        head = ngram[:1]\n",
    "        tail = ngram[1:]\n",
    "        for skip_tail in itertools.combinations(tail, n - 1):\n",
    "            if skip_tail[-1] is None:\n",
    "                continue\n",
    "            yield head + skip_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[], [0, 1, 2, 3], [4, 5, 6, 7, 8, 9, 10, 11],\n",
       "       [12, 13, 14, 15, 13, 16, 17, 13, 18, 19, 20, 21, 22, 23, 24, 25],\n",
       "       [26, 27, 28, 29, 30, 31, 14, 32, 33, 34, 35],\n",
       "       [4, 36, 37, 38, 14, 39, 40, 26, 41, 14, 42], [43, 9, 44, 14, 45],\n",
       "       [27, 46, 47, 48, 13, 49, 50],\n",
       "       [51, 14, 52, 53, 34, 54, 14, 55, 9, 56, 57], [58, 59, 60, 18, 61]], dtype=object)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_batch(sequence,window_size,filler=-1):\n",
    "    \n",
    "    '''Function which generates a set of batches from int-like sequence\n",
    "    default argument filler (-1) could be changed accoring to your needs'''\n",
    "    \n",
    "    batchesX = []\n",
    "    batchesY = []\n",
    "    \n",
    "    if len(sequence)>window_size: \n",
    "        \n",
    "        for index,num in enumerate(sequence):\n",
    "            range1 = sequence[index-window_size:index]\n",
    "            range2 = sequence[index+1:index+window_size+1]\n",
    "\n",
    "            if len(range1) is not window_size:\n",
    "                range1 = [filler]*(window_size-len(range1)) + range1\n",
    "\n",
    "            if len(range2) is not window_size:\n",
    "                range2 = range2 + [filler]*(window_size-len(range2))\n",
    "\n",
    "            batchesX.append(range1+range2)\n",
    "            batchesY.append(num)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        return None,None\n",
    "        \n",
    "    return (batchesX,batchesY)\n",
    "\n",
    "\n",
    "\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batches(enc_sequence,window_size=3): \n",
    "    \n",
    "    '''Function which iteratevely generate batches through encoded sequence'''\n",
    "    \n",
    "    batchesX=[]\n",
    "    batchesY=[]\n",
    "    \n",
    "    for value in enc_sequence:\n",
    "       \n",
    "        batchX , batchY = generate_batch(value,window_size)\n",
    "        \n",
    "        \n",
    "        if batchX is not None:\n",
    "            batchesX.append(np.array(batchX))\n",
    "            batchesY.append(np.array(batchY))\n",
    "            \n",
    "    return (np.array(batchesX),np.array(batchesY))\n",
    "    \n",
    "        \n",
    "              \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batchesX,batchesY=get_batches(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([[-1, -1, -1,  1,  2,  3],\n",
       "       [-1, -1, -1,  2,  3, -1],\n",
       "       [-1, -1, -1,  3, -1, -1],\n",
       "       [ 0,  1,  2, -1, -1, -1]]),\n",
       "       array([[-1, -1, -1,  5,  6,  7],\n",
       "       [-1, -1, -1,  6,  7,  8],\n",
       "       [-1, -1, -1,  7,  8,  9],\n",
       "       [ 4,  5,  6,  8,  9, 10],\n",
       "       [ 5,  6,  7,  9, 10, 11],\n",
       "       [ 6,  7,  8, 10, 11, -1],\n",
       "       [ 7,  8,  9, 11, -1, -1],\n",
       "       [ 8,  9, 10, -1, -1, -1]]),\n",
       "       array([[-1, -1, -1, 13, 14, 15],\n",
       "       [-1, -1, -1, 14, 15, 13],\n",
       "       [-1, -1, -1, 15, 13, 16],\n",
       "       [12, 13, 14, 13, 16, 17],\n",
       "       [13, 14, 15, 16, 17, 13],\n",
       "       [14, 15, 13, 17, 13, 18],\n",
       "       [15, 13, 16, 13, 18, 19],\n",
       "       [13, 16, 17, 18, 19, 20],\n",
       "       [16, 17, 13, 19, 20, 21],\n",
       "       [17, 13, 18, 20, 21, 22],\n",
       "       [13, 18, 19, 21, 22, 23],\n",
       "       [18, 19, 20, 22, 23, 24],\n",
       "       [19, 20, 21, 23, 24, 25],\n",
       "       [20, 21, 22, 24, 25, -1],\n",
       "       [21, 22, 23, 25, -1, -1],\n",
       "       [22, 23, 24, -1, -1, -1]]),\n",
       "       ...,\n",
       "       array([[   -1,    -1,    -1,     9,   778,    34],\n",
       "       [   -1,    -1,    -1,   778,    34,    14],\n",
       "       [   -1,    -1,    -1,    34,    14,  3940],\n",
       "       [   13,     9,   778,    14,  3940,     9],\n",
       "       [    9,   778,    34,  3940,     9, 14542],\n",
       "       [  778,    34,    14,     9, 14542,     9],\n",
       "       [   34,    14,  3940, 14542,     9, 12123],\n",
       "       [   14,  3940,     9,     9, 12123,    -1],\n",
       "       [ 3940,     9, 14542, 12123,    -1,    -1],\n",
       "       [    9, 14542,     9,    -1,    -1,    -1]]),\n",
       "       array([[    -1,     -1,     -1,     13,  16695,   2048],\n",
       "       [    -1,     -1,     -1,  16695,   2048,    163],\n",
       "       [    -1,     -1,     -1,   2048,    163,    244],\n",
       "       [   238,     13,  16695,    163,    244,     13],\n",
       "       [    13,  16695,   2048,    244,     13,     18],\n",
       "       [ 16695,   2048,    163,     13,     18,   6117],\n",
       "       [  2048,    163,    244,     18,   6117,    163],\n",
       "       [   163,    244,     13,   6117,    163,   3185],\n",
       "       [   244,     13,     18,    163,   3185, 183800],\n",
       "       [    13,     18,   6117,   3185, 183800,     -1],\n",
       "       [    18,   6117,    163, 183800,     -1,     -1],\n",
       "       [  6117,    163,   3185,     -1,     -1,     -1]]),\n",
       "       array([[   -1,    -1,    -1,     9,  5047,    34],\n",
       "       [   -1,    -1,    -1,  5047,    34,  7182],\n",
       "       [   -1,    -1,    -1,    34,  7182, 14323],\n",
       "       [ 9998,     9,  5047,  7182, 14323,    -1],\n",
       "       [    9,  5047,    34, 14323,    -1,    -1],\n",
       "       [ 5047,    34,  7182,    -1,    -1,    -1]])], dtype=object)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchesX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 loops, best of 3: 1.55 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit list(range(10)).append(list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 4.14 s per loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%timeit "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
