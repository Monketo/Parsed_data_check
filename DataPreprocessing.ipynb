{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Vocabscraper import VocabularyScraper\n",
    "import os\n",
    "import pickle\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from  nltk.tokenize import word_tokenize as tokenizer\n",
    "import itertools\n",
    "import string\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk import ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    ''' Helper function to load dataset '''\n",
    "    data=None\n",
    "    FILE_PATH= \"data\\words.pkl\"\n",
    "    if not os.path.exists(FILE_PATH):\n",
    "        os.makedirs(\"data\")\n",
    "        cursor = VocabularyScraper(None).db_executer\n",
    "        cursor.execute(\"SELECT term,definition FROM terms\")\n",
    "        data = cursor.fetchall()\n",
    "        with open(FILE_PATH,\"wb\") as file:\n",
    "            pickle.dump(data,file)\n",
    "    else:\n",
    "        with open(FILE_PATH,\"rb\") as file:\n",
    "            data = pickle.load(FILE_PATH)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def look_up_word(term):\n",
    "    for word in data_copy:\n",
    "        if word[1]==term:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_optimum_length(data,percentile):\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/words.pkl\",\"wb\") as file:\n",
    "    pickle.dump(words,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178200, '', 'giddy; frivolous; feather-headed &$ any thin, as on a board or a razor &$ the thin, new growth around the edge of a shell, of an oyster &$ having a feather-edge; also, having one edge thinner than the other, as a board; -- in the United States, said only of stuff one edge of which is made as thin as practicable &$ feverfew', None)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ex_remove_red_chars(*examples):\n",
    "    result=[]\n",
    "    for example in examples:\n",
    "        if example is not None:\n",
    "            punctuation=re.sub(\"[#$&]*\",\"\",string.punctuation)\n",
    "            punctuation = [char for char in punctuation]\n",
    "            del_patterns = [\"&[\\w]+&\",'”',\"^[\\s]\",\"“\",\"adj\\n\",\"v\\n\",\"n\\n\",\"adv\\n\"]\n",
    "            del_patterns.extend(punctuation)\n",
    "            for pattern in del_patterns:\n",
    "                example = example.replace(pattern,\"\")\n",
    "            example = re.split(r\"[&#$]*;*\",example) \n",
    "            \n",
    "            result.append(example)\n",
    "        else:\n",
    "            result.append(\"\")\n",
    "    return tuple(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tag_transform={\"adj\\\\n\":\"&JJ&\",\"v\\\\n\":\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548,\n",
       " 'adorn',\n",
       " 'furnish with power or authority; of kings or emperors &$ To make more beautiful and attractive; to decorate &$ make more attractive by adding ornament, colour, etc &$ be beautiful to look at &$ To adorn is to dress something up by decorating it. You might adorn your poncho with fringe or your poodle`s dog collar with rhinestones. &$ Adorn shares some Latin roots with words like ornament and ornate. So it makes sense that some people adorn their Christmas trees with tinsel and lights. Others adorn their eyelids with glitter. In any case, if you want to adorn yourself with all kinds of fabulous baubles, it might be wise to follow Coco Chanel`s advice: take at least one accessory off before you walk out the door. &$ v\\nmake more attractive by adding ornament, colour, etc. &$ v\\nbe beautiful to look at &$ v\\nfurnish with power or authority; of kings or emperors',\n",
       " 'None &$ &VBD& “Flowers adorned the tables everywhere”')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pos_tag in module nltk.tag:\n",
      "\n",
      "pos_tag(tokens, tagset=None, lang='eng')\n",
      "    Use NLTK's currently recommended part of speech tagger to\n",
      "    tag the given list of tokens.\n",
      "    \n",
      "        >>> from nltk.tag import pos_tag\n",
      "        >>> from nltk.tokenize import word_tokenize\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"))\n",
      "        [('John', 'NNP'), (\"'s\", 'POS'), ('big', 'JJ'), ('idea', 'NN'), ('is', 'VBZ'),\n",
      "        (\"n't\", 'RB'), ('all', 'PDT'), ('that', 'DT'), ('bad', 'JJ'), ('.', '.')]\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"), tagset='universal')\n",
      "        [('John', 'NOUN'), (\"'s\", 'PRT'), ('big', 'ADJ'), ('idea', 'NOUN'), ('is', 'VERB'),\n",
      "        (\"n't\", 'ADV'), ('all', 'DET'), ('that', 'DET'), ('bad', 'ADJ'), ('.', '.')]\n",
      "    \n",
      "    NB. Use `pos_tag_sents()` for efficient tagging of more than one sentence.\n",
      "    \n",
      "    :param tokens: Sequence of tokens to be tagged\n",
      "    :type tokens: list(str)\n",
      "    :param tagset: the tagset to be used, e.g. universal, wsj, brown\n",
      "    :type tagset: str\n",
      "    :param lang: the ISO 639 code of the language, e.g. 'eng' for English, 'rus' for Russian\n",
      "    :type lang: str\n",
      "    :return: The tagged tokens\n",
      "    :rtype: list(tuple(str, str))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_duplicates(data):\n",
    "    terms= set()\n",
    "    defs_exs=set()\n",
    "   \n",
    "    \n",
    "    for word in data_copy:\n",
    "        terms.add(word[1])\n",
    "        definitions,examples = word[2],word[3]\n",
    "        definitions,examples =  ex_remove_red_chars(definitions,examples)\n",
    "        defs_exs.update(definitions,examples)\n",
    "        \n",
    "    return(terms,defs_exs)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "terms , defs_exs = process_duplicates(data_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counter=Counter(defs_exs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_text = list(itertools.chain(*[sent.split() for sent in list(defs_exs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counter=Counter(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 426762),\n",
       " ('a', 420583),\n",
       " ('the', 402261),\n",
       " ('or', 263775),\n",
       " ('to', 256051),\n",
       " ('in', 173051),\n",
       " ('and', 158930),\n",
       " ('is', 84525),\n",
       " ('A', 79785),\n",
       " ('that', 78088)]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index=0\n",
    "word_to_index=dict()\n",
    "for key,indx in counter.items():\n",
    "    word_to_index[key]=index\n",
    "    index+=1\n",
    "for word in terms:\n",
    "    if word not in word_to_index:\n",
    "        word_to_index[word]=index\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_to_word=dict()\n",
    "for key,index in word_to_index.items():\n",
    "    index_to_word[index]=key\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290097, 'person', 'a human body (usually including the clothing &$ A single human being; an individual &$ A linguistic category used to distinguish between the speaker of an utterance and those to whom or about whom he is speaking. See grammatical person &$ one of three relations or conditions (that of speaking, that of being spoken to, and that of being spoken of) pertaining to a noun or a pronoun, and thence also to the verb of which it may be the subject &$ a living, self-conscious being, as distinct from an animal or a thing; a moral agent; a human being; a man, woman, or child &$ Someone who likes or has an affinity for (a specified thing &$ a character or part, as in a play; a specific kind or manifestation of individual character, whether in real life, or in literary or dramatic representation; an assumed character &$ the bodily form of a human being; body; outward appearance; as, of comely person &$ a grammatical category used in the classification of pronouns, possessive determiners, and verb forms according to whether they indicate the speaker, the addressee, or a third party &$ a human being spoken of indefinitely; one; a man; as, any person present &$ Any individual or formal organization with standing before the courts &$ a human being &$ a parson; the parish priest &$ to represent as a person; to personify; to impersonate &$ The physical human body seen as distinct from the mind, character etc &$ a shoot or bud of a plant; a polyp or zooid of the compound Hydrozoa Anthozoa, etc.; also, an individual, in the narrowest sense, among the higher animals &$ among Trinitarians, one of the three subdivisions of the Godhead (the Father, the Son, and the Holy Ghost); an hypostasis', None)\n"
     ]
    }
   ],
   "source": [
    "look_up_word(\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "for example in defs_exs:\n",
    "    sentence=[]\n",
    "    for word in example.split():\n",
    "        sentence.append(word_to_index[word])\n",
    "    sentences.append(sentence) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded=np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[], [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "       [8, 9, 10, 11, 12, 13, 14, 15, 13, 16], ...,\n",
       "       [780, 369, 15, 746, 697, 15, 2740, 14767, 13, 1109, 185059, 63, 291, 185060, 793, 15, 13, 688, 15, 13, 27535, 11714],\n",
       "       [369, 15, 746, 7300, 10300, 2308, 28, 9479, 13, 79168, 15, 9645, 63, 28, 190, 13, 3234, 7545, 15, 6453, 63, 3912, 83, 8520],\n",
       "       [8, 682, 6, 7891, 15, 30, 4376]], dtype=object)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skipgrams(sequence, n, k):\n",
    "    for ngram in ngrams(sequence, n + k, pad_right=True):\n",
    "        head = ngram[:1]\n",
    "        tail = ngram[1:]\n",
    "        for skip_tail in itertools.combinations(tail, n - 1):\n",
    "            if skip_tail[-1] is None:\n",
    "                continue\n",
    "            yield head + skip_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2, 3, 4, 5),\n",
       " (0, 1, 2, 3, 4, 6),\n",
       " (0, 1, 2, 3, 4, 7),\n",
       " (0, 1, 2, 3, 5, 6),\n",
       " (0, 1, 2, 3, 5, 7),\n",
       " (0, 1, 2, 3, 6, 7),\n",
       " (0, 1, 2, 4, 5, 6),\n",
       " (0, 1, 2, 4, 5, 7),\n",
       " (0, 1, 2, 4, 6, 7),\n",
       " (0, 1, 2, 5, 6, 7),\n",
       " (0, 1, 3, 4, 5, 6),\n",
       " (0, 1, 3, 4, 5, 7),\n",
       " (0, 1, 3, 4, 6, 7),\n",
       " (0, 1, 3, 5, 6, 7),\n",
       " (0, 1, 4, 5, 6, 7),\n",
       " (0, 2, 3, 4, 5, 6),\n",
       " (0, 2, 3, 4, 5, 7),\n",
       " (0, 2, 3, 4, 6, 7),\n",
       " (0, 2, 3, 5, 6, 7),\n",
       " (0, 2, 4, 5, 6, 7),\n",
       " (0, 3, 4, 5, 6, 7),\n",
       " (1, 2, 3, 4, 5, 6),\n",
       " (1, 2, 3, 4, 5, 7),\n",
       " (1, 2, 3, 4, 6, 7),\n",
       " (1, 2, 3, 5, 6, 7),\n",
       " (1, 2, 4, 5, 6, 7),\n",
       " (1, 3, 4, 5, 6, 7),\n",
       " (2, 3, 4, 5, 6, 7)]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(skipgrams(encoded[1],6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[], [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "       [8, 9, 10, 11, 12, 13, 14, 15, 13, 16], ...,\n",
       "       [780, 369, 15, 746, 697, 15, 2740, 14767, 13, 1109, 185059, 63, 291, 185060, 793, 15, 13, 688, 15, 13, 27535, 11714],\n",
       "       [369, 15, 746, 7300, 10300, 2308, 28, 9479, 13, 79168, 15, 9645, 63, 28, 190, 13, 3234, 7545, 15, 6453, 63, 3912, 83, 8520],\n",
       "       [8, 682, 6, 7891, 15, 30, 4376]], dtype=object)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(): \n",
    "    batches = []\n",
    "    window_size=3\n",
    "    \n",
    "    vocab_len = len(word_to_index)\n",
    "    for value in encoded[:10]:\n",
    "        length = len(value)\n",
    "        batch=None\n",
    "        \n",
    "        for index,word in enumerate(value):\n",
    "            if index-window_size<0:\n",
    "                range1= value[0:index]\n",
    "                range2= value[index+1:index+window_size+(window_size-len(range1))+1]\n",
    "                batch=range1+range2\n",
    "                print(batch)\n",
    "                \n",
    "            if index >= length - window_size :\n",
    "                range1= value[index-window_size-window_size-len(range2):index+1]\n",
    "                range2=value[index+1:length]\n",
    "                batch=range1+range2\n",
    "            else:\n",
    "                batch=value[index-window_size:index]+value[index+1:index+window_size+1]\n",
    "                \n",
    "                \n",
    "            batches.append(batch)    \n",
    "              \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 96, 97, 30, 98]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = [len(ex) for ex in defs_exs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df= pandas.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>706896.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>72.132277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73.427707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15%</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>415.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2466.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  706896.000000\n",
       "mean       72.132277\n",
       "std        73.427707\n",
       "min         0.000000\n",
       "15%        23.000000\n",
       "50%        50.000000\n",
       "90%       142.000000\n",
       "99%       415.000000\n",
       "max      2466.000000"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(percentiles=[.15, .90, .99])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
