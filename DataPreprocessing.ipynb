{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Vocabscraper import VocabularyScraper\n",
    "import os\n",
    "import pickle\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from  nltk.tokenize import word_tokenize as tokenizer\n",
    "import itertools\n",
    "import string\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk import ngrams\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data(preprocessed=False):\n",
    "    \n",
    "    ''' Helper function to load dataset '''\n",
    "    data=None\n",
    "    FILE_PATH= \"words.pkl\"\n",
    "    if not os.path.exists(FILE_PATH):\n",
    "        cursor = VocabularyScraper(None).db_executer\n",
    "        cursor.execute(\"SELECT term,definitions,examples FROM terms\")\n",
    "        data = cursor.fetchall()\n",
    "        with open(FILE_PATH,\"wb\") as file:\n",
    "            pickle.dump(data,file)\n",
    "    else:\n",
    "        with open(FILE_PATH,\"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def look_up_word(term,data):\n",
    "    '''Name of the function is self-explanatory '''\n",
    "        \n",
    "    for word in data:\n",
    "        if word[0]==term:\n",
    "            return word\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_optimum_length(defs_exs,percentiles):\n",
    "    \n",
    "    '''Name of the function is self-explanatory '''\n",
    "    \n",
    "    stats = [len(ex) for ex in defs_exs]\n",
    "    df= pandas.DataFrame(stats,columns=[\"length of samples\"])\n",
    "    return df.describe(percentiles=percentiles)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ex_remove_red_chars(*examples):\n",
    "    \n",
    "    ''' Function to remove redundant chars , like punctuation or part of speech markers\n",
    "        Then to split them using \"#$\" or \"&#\" delimiters'''\n",
    "    \n",
    "    result=[]\n",
    "    for example in examples:\n",
    "        if example is not None:\n",
    "            punctuation=re.sub(\"[#$&]*\",\"\",string.punctuation)\n",
    "            punctuation = [char for char in punctuation]\n",
    "            del_patterns = [\"&[\\w]+&\",'”',\"^[\\s]\",\"“\",\"adj\\n\",\"v\\n\",\"n\\n\",\"adv\\n\"]\n",
    "            del_patterns.extend(punctuation)\n",
    "            for pattern in del_patterns:\n",
    "                example = example.replace(pattern,\"\")\n",
    "            example = re.split(r\"[&#$]*;*\",example) \n",
    "            \n",
    "            result.append(example)\n",
    "        else:\n",
    "            result.append(\"\")\n",
    "    return tuple(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_duplicates(data):\n",
    "    ''' Function to avoid storing unneccessary duplicates'''\n",
    "    \n",
    "    terms= set()\n",
    "    defs_exs=set()\n",
    "   \n",
    "    \n",
    "    for word in data:\n",
    "        terms.add(word[0])\n",
    "        definitions,examples = word[1],word[2]\n",
    "        definitions,examples =  ex_remove_red_chars(definitions,examples)\n",
    "        defs_exs.update(definitions,examples)\n",
    "        \n",
    "    return(terms,defs_exs)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "terms , defs_exs = process_duplicates(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_dicts(terms,defs_and_exs):\n",
    "    \n",
    "    ''' Function to create helping dictionaries for future word-to-integers (or conversely) conversion'''\n",
    "    \n",
    "    all_text = list(itertools.chain(*[sent.split() for sent in list(defs_exs)]))\n",
    "    counter=Counter(all_text)\n",
    "    index=0\n",
    "    word_to_index=dict()\n",
    "    \n",
    "    for key,indx in counter.items():\n",
    "        word_to_index[key]=index\n",
    "        index+=1\n",
    "        \n",
    "    #Terms should be treated differently,avoiding split,that's why we add them seperately\n",
    "    \n",
    "    for word in terms:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word]=index\n",
    "            index+=1\n",
    "            \n",
    "    index_to_word=dict()\n",
    "    \n",
    "    for key,index in word_to_index.items():\n",
    "        index_to_word[index]=key\n",
    "    return (word_to_index,index_to_word)    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_to_index,index_to_word = create_lookup_dicts(terms,defs_exs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('god',\n",
       " 'A god is a supreme being or deity, and it`s spelled with a lowercase g when you`re not referring to the God of Christian, Jewish, or Muslim tradition. The ancient Greeks had many gods — including Zeus, Apollo, and Poseidon. &$ A physical representation of a deity is also called a god. If you go to Hawaii, you can even buy a god in a gift shop — a statue or idol that represents one of the Hawaiian gods, like a figure of the god Pele. The word god also refers to a man of superior quality or exceptional beauty. Elvis Presley was considered a god by many teenage girls in the late 1950s. &$ n\\nany supernatural being worshipped as controlling some part of the world or some aspect of life or who is the personification of a force &$ n\\na man of such superior qualities that he seems like a deity to other people &$ n\\na material effigy that is worshipped &$ n\\nthe supernatural being conceived as the perfect and omnipotent and omniscient originator and ruler of the universe; the object of worship in monotheistic religions &$ a person or thing deified and honored as the chief good; an object of supreme regard &$ any supernatural being worshipped as controlling some part of the world or some aspect of life or who is the personification of a force &$ to idolize &$ The (personification of the) laws of nature &$ figuratively applied to one who wields great or despotic power &$ A person in a high position of authority; a powerful ruler or tyrant &$ A deity &$ a material effigy that is worshipped &$ An idol &$ the Supreme Being; the eternal and infinite Spirit, the Creator, and the Sovereign of the universe; Jehovah &$ An impersonal and universal spiritual presence or force &$ The single deity of various monotheistic religions &$ The person who owns and runs a multi-user dungeon &$ An omnipotent being, creator of the universe (as in deism &$ The single male deity of various duotheistic religions &$ The Horned God &$ An exceedingly handsome man &$ a being conceived of as possessing supernatural power, and to be propitiated by sacrifice, worship, etc.; a divinity; a deity; an object of worship; an idol &$ the supernatural being conceived as the perfect and omnipotent and omniscient originator and ruler of the universe; the object of worship in monotheistic religions &$ to treat as a god; to idolize &$ to deify &$ a man of such superior qualities that he seems like a deity to other people',\n",
       " '&NN& “he was a god among men” &$ &NN& “money was his god” &$ ')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_up_word(\"god\",words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode(defs_exs,word2int):\n",
    "    '''Function to encode words to integers'''\n",
    "    sentences=[]\n",
    "    for example in defs_exs:\n",
    "        sentence=[]\n",
    "        for word in example.split():\n",
    "            sentence.append(word2int[word])\n",
    "        sentences.append(sentence) \n",
    "    encoded=np.array(sentences)\n",
    "    return encoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoded=encode(defs_exs,word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[], [0, 1, 2, 3, 4, 5],\n",
       "       [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], ...,\n",
       "       [547, 9, 659, 50, 8422, 136477, 40090, 56, 2266, 157, 3773, 141, 7692, 26436],\n",
       "       [9316, 2754, 24958, 302, 2322, 1987, 3973, 5169],\n",
       "       [1851, 4490, 13909, 6010, 56, 0, 9073, 96793, 0, 9073, 867]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def skipgrams(sequence, n, k):\n",
    "    ''' Can be deleted , was used for testing'''\n",
    "    for ngram in ngrams(sequence, n + k, pad_right=True):\n",
    "        head = ngram[:1]\n",
    "        tail = ngram[1:]\n",
    "        for skip_tail in itertools.combinations(tail, n - 1):\n",
    "            if skip_tail[-1] is None:\n",
    "                continue\n",
    "            yield head + skip_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[], [0, 1, 2, 3, 4, 5],\n",
       "       [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [15, 7, 20, 21, 22, 0, 23],\n",
       "       [0, 24, 25, 7, 26, 27, 28, 29, 30, 28, 31, 32, 33, 34],\n",
       "       [35, 36, 13, 37, 38, 39, 40, 41, 42, 0, 43, 44, 36, 45, 46, 47, 48, 49, 50, 51, 13, 43, 50, 52, 53, 54, 55, 56, 57, 9, 13, 58, 59, 60, 61],\n",
       "       [62, 63, 64, 65, 66],\n",
       "       [13, 67, 38, 68, 69, 15, 70, 71, 72, 32, 13, 73, 38, 74, 75, 76, 50, 77],\n",
       "       [78, 79, 80, 60, 81, 82, 60, 83, 9, 84], [0, 85, 9, 86, 38, 87]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_batch(sequence,window_size,filler=-1):\n",
    "    \n",
    "    '''Function which generates a set of batches from int-like sequence\n",
    "    default argument filler (-1) could be changed accoring to your needs'''\n",
    "    \n",
    "    batchesX = []\n",
    "    batchesY = []\n",
    "    \n",
    "    if len(sequence)>window_size: \n",
    "        \n",
    "        for index,num in enumerate(sequence):\n",
    "            range1 = sequence[index-window_size:index]\n",
    "            range2 = sequence[index+1:index+window_size+1]\n",
    "\n",
    "            if len(range1) is not window_size:\n",
    "                range1 = [filler]*(window_size-len(range1)) + range1\n",
    "\n",
    "            if len(range2) is not window_size:\n",
    "                range2 = range2 + [filler]*(window_size-len(range2))\n",
    "\n",
    "            batchesX.append(range1+range2)\n",
    "            batchesY.append(num)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        return None,None\n",
    "        \n",
    "    return (batchesX,batchesY)\n",
    "\n",
    "\n",
    "\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_batches(enc_sequences,window_size=3): \n",
    "    \n",
    "    '''Function which iteratevely generate batches through encoded sequence'''\n",
    "    \n",
    "    batchesX=[]\n",
    "    batchesY=[]\n",
    "    for value in enc_sequences:\n",
    "        batchX , batchY = generate_batch(value,window_size)\n",
    "        if batchX is not None:\n",
    "            batchesX.append(np.array(batchX,dtype=np.int32))\n",
    "            batchesY.append(np.array(batchY,dtype=np.int32))\n",
    "            \n",
    "    return (batchesX,batchesY)\n",
    "    \n",
    "        \n",
    "              \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batchesX,batchesY=generate_batches(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_batch(batchesX,batchesY,batch_size=256):\n",
    "    \n",
    "    '''Batch generator in order to save some computation time'''\n",
    "    batches=generate_empty_2D_batch_array()\n",
    "    for batch in zip(batchesX,batchesY):\n",
    "        for i in range(len(batch[0])):\n",
    "            X_sample = batch[0][i] \n",
    "            Y_sample = batch[1][i]\n",
    "            one_batch = np.array([[X_sample,Y_sample]])\n",
    "            batches=np.append(batches,one_batch,axis=0)\n",
    "            if len(batches)==batch_size:\n",
    "                yield batches\n",
    "                batches=generate_empty_2D_batch_array()\n",
    "        \n",
    "     \n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_empty_2D_batch_array():\n",
    "    ''' Name of function is self-explanatory'''\n",
    "    \n",
    "    arr = np.array([])\n",
    "    arr = arr.reshape(-1,2)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Word2Vec:\n",
    "    \n",
    "    def __init__(self,batch_size,word_to_int,embedding_size,learning_rate,training_steps):\n",
    "        \n",
    "        self.batch_size=batch_size\n",
    "        self.vocab_len=len(word_to_int)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.training_steps=training_steps\n",
    "       \n",
    "        \n",
    "    def train_word2vec(self):\n",
    "        with tf.name_scope(\"data\"):\n",
    "            center_words = tf.placeholder(dtype=tf.int32,shape=[self.batch_size],name=\"center_words\")\n",
    "            target_words = tf.placeholder(dtype=tf.int32,shape=[self.batch_size,1],name=\"target_words\")\n",
    "        with tf.name_scope(\"embed\"):\n",
    "            embedding_matrix = tf.Variable(tf.random_uniform([self.vocab_len,self.embedding_size],-1.0,1.0),name=\"embedding_matrix\")\n",
    "            \n",
    "        with tf.name_scope(\"loss\"):\n",
    "            embedding = tf.nn.embedding_lookup(embedding_matrix,center_words,name=\"embed\")\n",
    "            nce_weights = tf.Variable(tf.truncated_normal([self.vocab_len,self.embedding_size],stddev=1/(self.embedding_size**0.5)),\n",
    "                                      name=\"nce_weights\")\n",
    "            nce_biases = tf.Variable(tf.zeros([self.vocab_len]),name=\"nce_biases\")\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights, \n",
    "                                            biases=nce_biases, \n",
    "                                            labels=target_words, \n",
    "                                            inputs=embedding, \n",
    "                                            num_sampled=64, \n",
    "                                            num_classes=self.vocab_len), name='loss')\n",
    "                                     \n",
    "                                     \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        batch_gen = gen_batch(batchesX,batchesY,self.batch_size)\n",
    "        average_loss=0.0\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(self.training_steps):\n",
    "                batch = next(batch_gen)\n",
    "                center_word = batch[:,1]\n",
    "                target_word = batch[:,0]\n",
    "                loss_get,_ = sess.run([loss,optimizer],feed_dict={center_words:center_word,\n",
    "                                                              target_words:target_word})\n",
    "                average_loss+=loss_get\n",
    "                \n",
    "                if (i+1) % 100==0:\n",
    "                    print(\"Average loss at timestep {} is {:5.1f} \".format(i+1,\n",
    "                                                                           average_loss/i+1))\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(batch_size=256,embedding_size=300,word_to_int=word_to_index,learning_rate=0.001,training_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (256, 6) for Tensor 'data_2/target_words:0', which has shape '(256, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-eba8f8f5ab96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-116846720b43>\u001b[0m in \u001b[0;36mtrain_word2vec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mtarget_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 loss_get,_ = sess.run([loss,optimizer],feed_dict={center_words:center_word,\n\u001b[0;32m---> 49\u001b[0;31m                                                               target_words:target_word})\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0maverage_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    945\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (256, 6) for Tensor 'data_2/target_words:0', which has shape '(256, 1)'"
     ]
    }
   ],
   "source": [
    "model.train_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen=gen_batch(batchesX,batchesY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val=next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1,  -1,  -1,   1,   2,   3],\n",
       "       [ -1,  -1,  -1,   2,   3,   4],\n",
       "       [ -1,  -1,  -1,   3,   4,   5],\n",
       "       ..., \n",
       "       [ 38, 175, 176,  13, 177, 178],\n",
       "       [175, 176,  38, 177, 178, 112],\n",
       "       [176,  38,  13, 178, 112, 179]], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(val[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert all(x.shape == (6,) for x in val[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
